{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "material-nursery",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "soviet-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "DATA_PATH = Path(\"data\")\n",
    "PATH = DATA_PATH / \"mnist\"\n",
    "\n",
    "PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"https://github.com/pytorch/tutorials/raw/master/_static/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "if not (PATH / FILENAME).exists():\n",
    "        content = requests.get(URL + FILENAME).content\n",
    "        (PATH / FILENAME).open(\"wb\").write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "rising-collection",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "\n",
    "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "alleged-electron",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21721c7b4f0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[2].reshape((28,28)),cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "allied-justice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "rural-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the numpy data into tensor\n",
    "x_train,y_train,x_test,y_test = map(torch.tensor,(x_train,y_train,x_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "reserved-series",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([5, 0, 4,  ..., 8, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "print(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "present-collapse",
   "metadata": {},
   "outputs": [],
   "source": [
    "n,c = x_train.shape\n",
    "bs = 64\n",
    "lr=1e-6\n",
    "N_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "nutritional-commission",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader\n",
    "train_ds = TensorDataset(x_train,y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)\n",
    "\n",
    "valid_ds = TensorDataset(x_test,y_test)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=bs * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "modified-playlist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the network using NN module\n",
    "class MnistLogistic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(c,10)\n",
    "    \n",
    "    def forward(self,xb):\n",
    "        return self.linear(xb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "injured-posting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = MnistLogistic()\n",
    "    return model, torch.optim.RMSprop(model.parameters(),lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "funky-ozone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the dependencies before training\n",
    "model,opt = get_model()\n",
    "lossfn = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "transparent-ireland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model,lossfn,xb,yb,opt):\n",
    "    pred = model(xb)\n",
    "    loss = lossfn(pred,yb)\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    return loss.item(), len(xb)\n",
    "\n",
    "\n",
    "def fit(N_epochs, model, lossfn, opt, train_dl, valid_dl):\n",
    "    for epoch in range(N_epochs):\n",
    "        model.train()\n",
    "        \n",
    "        for xb,yb in train_dl:\n",
    "            loss_batch(model,lossfn,xb,yb,opt)\n",
    "        model.eval()\n",
    "\n",
    "        # Validation loss\n",
    "        with torch.no_grad():\n",
    "            valid_loss = sum(lossfn(model(xb), yb) for xb, yb in valid_dl)\n",
    "        print(epoch, valid_loss / len(valid_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "breathing-sauce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(2.2851)\n",
      "1 tensor(2.2561)\n",
      "2 tensor(2.2277)\n",
      "3 tensor(2.1997)\n",
      "4 tensor(2.1722)\n",
      "5 tensor(2.1453)\n",
      "6 tensor(2.1188)\n",
      "7 tensor(2.0927)\n",
      "8 tensor(2.0669)\n",
      "9 tensor(2.0416)\n",
      "10 tensor(2.0167)\n",
      "11 tensor(1.9921)\n",
      "12 tensor(1.9679)\n",
      "13 tensor(1.9441)\n",
      "14 tensor(1.9207)\n",
      "15 tensor(1.8976)\n",
      "16 tensor(1.8748)\n",
      "17 tensor(1.8523)\n",
      "18 tensor(1.8301)\n",
      "19 tensor(1.8083)\n",
      "20 tensor(1.7868)\n",
      "21 tensor(1.7657)\n",
      "22 tensor(1.7448)\n",
      "23 tensor(1.7242)\n",
      "24 tensor(1.7040)\n",
      "25 tensor(1.6840)\n",
      "26 tensor(1.6643)\n",
      "27 tensor(1.6450)\n",
      "28 tensor(1.6259)\n",
      "29 tensor(1.6071)\n",
      "30 tensor(1.5886)\n",
      "31 tensor(1.5704)\n",
      "32 tensor(1.5526)\n",
      "33 tensor(1.5349)\n",
      "34 tensor(1.5175)\n",
      "35 tensor(1.5005)\n",
      "36 tensor(1.4837)\n",
      "37 tensor(1.4672)\n",
      "38 tensor(1.4509)\n",
      "39 tensor(1.4349)\n",
      "40 tensor(1.4192)\n",
      "41 tensor(1.4037)\n",
      "42 tensor(1.3885)\n",
      "43 tensor(1.3735)\n",
      "44 tensor(1.3588)\n",
      "45 tensor(1.3443)\n",
      "46 tensor(1.3301)\n",
      "47 tensor(1.3162)\n",
      "48 tensor(1.3024)\n",
      "49 tensor(1.2888)\n",
      "50 tensor(1.2756)\n",
      "51 tensor(1.2625)\n",
      "52 tensor(1.2496)\n",
      "53 tensor(1.2370)\n",
      "54 tensor(1.2246)\n",
      "55 tensor(1.2124)\n",
      "56 tensor(1.2004)\n",
      "57 tensor(1.1886)\n",
      "58 tensor(1.1771)\n",
      "59 tensor(1.1657)\n",
      "60 tensor(1.1546)\n",
      "61 tensor(1.1436)\n",
      "62 tensor(1.1329)\n",
      "63 tensor(1.1223)\n",
      "64 tensor(1.1119)\n",
      "65 tensor(1.1017)\n",
      "66 tensor(1.0916)\n",
      "67 tensor(1.0818)\n",
      "68 tensor(1.0721)\n",
      "69 tensor(1.0626)\n",
      "70 tensor(1.0532)\n",
      "71 tensor(1.0440)\n",
      "72 tensor(1.0350)\n",
      "73 tensor(1.0261)\n",
      "74 tensor(1.0174)\n",
      "75 tensor(1.0088)\n",
      "76 tensor(1.0004)\n",
      "77 tensor(0.9921)\n",
      "78 tensor(0.9839)\n",
      "79 tensor(0.9759)\n",
      "80 tensor(0.9681)\n",
      "81 tensor(0.9603)\n",
      "82 tensor(0.9528)\n",
      "83 tensor(0.9453)\n",
      "84 tensor(0.9379)\n",
      "85 tensor(0.9307)\n",
      "86 tensor(0.9236)\n",
      "87 tensor(0.9167)\n",
      "88 tensor(0.9098)\n",
      "89 tensor(0.9031)\n",
      "90 tensor(0.8964)\n",
      "91 tensor(0.8899)\n",
      "92 tensor(0.8835)\n",
      "93 tensor(0.8772)\n",
      "94 tensor(0.8710)\n",
      "95 tensor(0.8649)\n",
      "96 tensor(0.8589)\n",
      "97 tensor(0.8530)\n",
      "98 tensor(0.8472)\n",
      "99 tensor(0.8415)\n"
     ]
    }
   ],
   "source": [
    "fit(N_epochs,model,lossfn,opt,train_dl,valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "delayed-playlist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction  5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21721983bb0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAL4ElEQVR4nO3dTahc5R3H8d+vVjcqNKk0hJjWF9wVGkvIpqEmiJJmE92IWZRIpbeLCnZnsIvcSxGkVEtXwhWDsVhFMNYggqZyk7QbyU1IY16qSSViwjWppKVxZdV/F3Mi1zgz5+a8zJnc//cDw8yceTl/TvK7zznnmec8jggBWPy+0XUBAEaDsANJEHYgCcIOJEHYgSS+OcqV2ebUP9CyiHC/5bVadtsbbL9r+6TtrXW+C0C7XLWf3fZVkt6TdJek05L2S9ocEceGfIaWHWhZGy37GkknI+L9iPhU0ouSNtX4PgAtqhP2FZI+nPf8dLHsK2xP2J61PVtjXQBqav0EXURMS5qW2I0HulSnZT8jaeW85zcWywCMoTph3y/pNts3275G0v2SdjVTFoCmVd6Nj4jPbD8k6Q1JV0naHhFHG6sMQKMqd71VWhnH7EDrWvlRDYArB2EHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJVJ6yGZCkycnJoa/fcccdlb977969lT8rldeWTa2w2z4l6YKkzyV9FhGrmygKQPOaaNnXR8THDXwPgBZxzA4kUTfsIelN2wdsT/R7g+0J27O2Z2uuC0ANdXfj10bEGdvfkbTb9j8iYt/8N0TEtKRpSbIdNdcHoKJaLXtEnCnuz0l6RdKaJooC0LzKYbd9re3rLz6WdLekI00VBqBZjqi2Z237FvVac6l3OPCniHis5DPsxo+Zuv3k69ata66Yhq1fv37ga3v27BldISMWEe63vPIxe0S8L+kHlSsCMFJ0vQFJEHYgCcIOJEHYgSQIO5AEQ1wXgWHdXzMzM6MrZMTKus8Wc/daFbTsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE/exXgLJhpF32pU9NTVX+bNnw2bJLSXOp6MtDyw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSVS+lHSllXEp6Ura/DcqG/M97HLMGE+DLiVNyw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTCefQx0OS67znh0XFlKW3bb222fs31k3rKltnfbPlHcL2m3TAB1LWQ3/llJGy5ZtlXSWxFxm6S3iucAxlhp2CNin6TzlyzeJGlH8XiHpHuaLQtA06oesy+LiLni8UeSlg16o+0JSRMV1wOgIbVP0EVEDBvgEhHTkqYlBsIAXara9XbW9nJJKu7PNVcSgDZUDfsuSVuKx1skvdpMOQDaUjqe3fYLktZJukHSWUnbJP1Z0kuSvivpA0n3RcSlJ/H6fRe78X2UXfe97Lrxddh9hz7jCjZoPHvpMXtEbB7w0p21KgIwUvxcFkiCsANJEHYgCcIOJEHYgSQY4joCZV1nbXatARfRsgNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjGcfgXEer152KfH169cPfX3Pnj0NVoM20bIDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBL0s2Oosumky0xNTQ18bXJystZ34/KUtuy2t9s+Z/vIvGWTts/YPlTcNrZbJoC6FrIb/6ykDX2W/z4iVhW315stC0DTSsMeEfsknR9BLQBaVOcE3UO2Dxe7+UsGvcn2hO1Z27M11gWgpqphf0rSrZJWSZqT9MSgN0bEdESsjojVFdcFoAGVwh4RZyPi84j4QtLTktY0WxaAplUKu+3l857eK+nIoPcCGA8uG89s+wVJ6yTdIOmspG3F81WSQtIpSb+IiLnSldnDV7ZIlY1nr9uXjf6y9vFHhPstL/1RTURs7rP4mdoVARgpfi4LJEHYgSQIO5AEYQeSIOxAEgxxHYGyyy2XXa65zqWot23bVvmzWFxo2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCfrZx0BZP3ydaZHrDuWs+3n6+ccHLTuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJFF6KelGV5b0UtLor+3/e8N+n1B2DYEr2aBLSdOyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAS9LOjM6P8v3cpu29X9KJQuZ/d9krbM7aP2T5q++Fi+VLbu22fKO6XNF00gOaUtuy2l0taHhEHbV8v6YCkeyQ9IOl8RDxue6ukJRHxSMl30bLjS7Ts7ajcskfEXEQcLB5fkHRc0gpJmyTtKN62Q70/AADG1GVdg872TZJul/S2pGURMVe89JGkZQM+MyFpokaNABqw4BN0tq+TtFfSYxGx0/Z/IuJb817/d0QMPW5nNx7zsRvfjloDYWxfLellSc9HxM5i8dnieP7icf25JgoF0I7S3Xj3/gQ+I+l4RDw576VdkrZIery4f7WVCnFFq3sp6jqmpqY6W/c4Wsgx+48k/VTSO7YPFcseVS/kL9l+UNIHku5rpUIAjSgNe0T8TdKgA5w7my0HQFv4uSyQBGEHkiDsQBKEHUiCsANJMGUzhpqZmRn6+rp160ZTSB9ll4OuM9X1YkTLDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ0M+eXJdXiynrBy8bj04/+uWhZQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJOhnX+TqXre9rC977969ra4fzaFlB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkXDae2fZKSc9JWiYpJE1HxB9sT0r6uaR/FW99NCJeL/mu7gZPA0lERN9ZlxcS9uWSlkfEQdvXSzog6R715mP/JCJ+t9AiCDvQvkFhX8j87HOS5orHF2wfl7Si2fIAtO2yjtlt3yTpdklvF4sesn3Y9nbbSwZ8ZsL2rO3ZeqUCqKN0N/7LN9rXSdor6bGI2Gl7maSP1TuO/416u/o/K/kOduOBllU+Zpck21dLek3SGxHxZJ/Xb5L0WkR8v+R7CDvQskFhL92Nt21Jz0g6Pj/oxYm7i+6VdKRukQDas5Cz8Wsl/VXSO5K+KBY/KmmzpFXq7cafkvSL4mTesO+iZQdaVms3vimEHWhf5d14AIsDYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IIlRT9n8saQP5j2/oVg2jsa1tnGtS6K2qpqs7XuDXhjpePavrdyejYjVnRUwxLjWNq51SdRW1ahqYzceSIKwA0l0Hfbpjtc/zLjWNq51SdRW1Uhq6/SYHcDodN2yAxgRwg4k0UnYbW+w/a7tk7a3dlHDILZP2X7H9qGu56cr5tA7Z/vIvGVLbe+2faK47zvHXke1Tdo+U2y7Q7Y3dlTbStszto/ZPmr74WJ5p9tuSF0j2W4jP2a3fZWk9yTdJem0pP2SNkfEsZEWMoDtU5JWR0TnP8Cw/WNJn0h67uLUWrZ/K+l8RDxe/KFcEhGPjEltk7rMabxbqm3QNOMPqMNt1+T051V00bKvkXQyIt6PiE8lvShpUwd1jL2I2Cfp/CWLN0naUTzeod5/lpEbUNtYiIi5iDhYPL4g6eI0451uuyF1jUQXYV8h6cN5z09rvOZ7D0lv2j5ge6LrYvpYNm+arY8kLeuymD5Kp/EepUumGR+bbVdl+vO6OEH3dWsj4oeSfiLpl8Xu6liK3jHYOPWdPiXpVvXmAJyT9ESXxRTTjL8s6VcR8d/5r3W57frUNZLt1kXYz0haOe/5jcWysRARZ4r7c5JeUe+wY5ycvTiDbnF/ruN6vhQRZyPi84j4QtLT6nDbFdOMvyzp+YjYWSzufNv1q2tU262LsO+XdJvtm21fI+l+Sbs6qONrbF9bnDiR7Wsl3a3xm4p6l6QtxeMtkl7tsJavGJdpvAdNM66Ot13n059HxMhvkjaqd0b+n5J+3UUNA+q6RdLfi9vRrmuT9IJ6u3X/U+/cxoOSvi3pLUknJP1F0tIxqu2P6k3tfVi9YC3vqLa16u2iH5Z0qLht7HrbDalrJNuNn8sCSXCCDkiCsANJEHYgCcIOJEHYgSQIO5AEYQeS+D+mQvm9u0Ov7AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Prediction \",model(x_test[10]).detach().numpy().argmax())\n",
    "plt.imshow(x_test[10].numpy().reshape((28,28)),cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-western",
   "metadata": {},
   "source": [
    "## Using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-horror",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
