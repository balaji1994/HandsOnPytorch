{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dramatic-retreat",
   "metadata": {},
   "source": [
    "Download the dataset here https://www.kaggle.com/arshid/iris-flower-dataset and place it inside `./data/iris`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "saving-source",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "import pickle\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "soviet-renewal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "political-norman",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisDataset():\n",
    "    def __init__(self):\n",
    "        df = pd.read_csv(\"./data/iris/IRIS.csv\",skiprows=1)\n",
    "        labels = df.iloc[:,-1]\n",
    "        self.x = torch.from_numpy(df.iloc[:,:-1].values.astype(\"float32\"))\n",
    "        self.y = torch.from_numpy(self._encode_labels(labels)).type(torch.LongTensor)\n",
    "        self.n_samples = len(df)\n",
    "        \n",
    "    def _encode_labels(self,arr):\n",
    "        encoder = LabelEncoder()\n",
    "        _encoded = encoder.fit_transform(arr)\n",
    "        output = open(\"./data/iris/iris_labels.pkl\",\"wb\")\n",
    "        pickle.dump(encoder,output)\n",
    "        return _encoded.astype(\"float32\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index], self.y[index]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "generous-panel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.8000, 2.7000, 5.1000, 1.9000]) tensor(2)\n"
     ]
    }
   ],
   "source": [
    "dataset = IrisDataset()\n",
    "feature,label = dataset[100]\n",
    "print(feature,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "spread-crossing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_dataset(dataset, val_split=0.25):\n",
    "    train_idx, val_idx = train_test_split(list(range(len(dataset))), test_size=val_split)\n",
    "    datasets = {}\n",
    "    datasets['train'] = Subset(dataset, train_idx)\n",
    "    datasets['val'] = Subset(dataset, val_idx)\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "binary-intensity",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = train_val_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "higher-hungarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(ds['train'].dataset,batch_size=4,shuffle=True)\n",
    "valid_loader = DataLoader(ds['val'].dataset,batch_size=4*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "excess-serial",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.fc1 = nn.Linear(4,4)\n",
    "    \n",
    "    def forward(self,xb):\n",
    "        xb = self.fc1(xb)\n",
    "        return xb\n",
    "        \n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "nearby-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossfn = F.cross_entropy\n",
    "opt = torch.optim.SGD(net.parameters(),1e-2,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "stretch-departure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(n_epochs, model, lossfn, opt, train_dl, valid_dl):\n",
    "    print(\"Staring Training\")\n",
    "    for epoch in range(n_epochs):\n",
    "        running_loss = 0.0\n",
    "        model.train()\n",
    "        i = 0\n",
    "        for xb, yb in train_dl:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            pred = model(xb)\n",
    "            loss = lossfn(pred,yb)\n",
    "            opt.zero_grad()\n",
    "            \n",
    "            loss.backward()\n",
    "            # Gradient descent updating weights\n",
    "            opt.step()\n",
    "            i+=1\n",
    "        model.eval()\n",
    "        \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        # Validation loss\n",
    "        with torch.no_grad():\n",
    "            valid_loss = sum(lossfn(model(xb.to(device)), yb.to(device)) for xb, yb in valid_dl)\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs} loss {running_loss} val_loss {valid_loss / len(valid_dl)}\")\n",
    "        running_loss = 0.0\n",
    "    print(\"Training Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "tutorial-reference",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staring Training\n",
      "Epoch 1/50 loss 1.4166115522384644 val_loss 0.5103714466094971\n",
      "Epoch 2/50 loss 0.3130640685558319 val_loss 0.39526644349098206\n",
      "Epoch 3/50 loss 0.378709614276886 val_loss 0.3339281976222992\n",
      "Epoch 4/50 loss 0.29653477668762207 val_loss 0.2905538082122803\n",
      "Epoch 5/50 loss 0.048768773674964905 val_loss 0.3764844834804535\n",
      "Epoch 6/50 loss 0.6326228976249695 val_loss 0.5171579122543335\n",
      "Epoch 7/50 loss 1.580254077911377 val_loss 0.2976049780845642\n",
      "Epoch 8/50 loss 0.458731472492218 val_loss 0.207060307264328\n",
      "Epoch 9/50 loss 0.08319688588380814 val_loss 0.19943152368068695\n",
      "Epoch 10/50 loss 0.05798394978046417 val_loss 0.18840889632701874\n",
      "Epoch 11/50 loss 1.1027641296386719 val_loss 0.1869998723268509\n",
      "Epoch 12/50 loss 0.12191270291805267 val_loss 0.18015141785144806\n",
      "Epoch 13/50 loss 0.9407714605331421 val_loss 0.1925995945930481\n",
      "Epoch 14/50 loss 0.7263658046722412 val_loss 0.15742425620555878\n",
      "Epoch 15/50 loss 0.04012030363082886 val_loss 0.15928487479686737\n",
      "Epoch 16/50 loss 1.0852916240692139 val_loss 0.33289894461631775\n",
      "Epoch 17/50 loss 0.02120385505259037 val_loss 0.15822724997997284\n",
      "Epoch 18/50 loss 0.009092945605516434 val_loss 0.17523668706417084\n",
      "Epoch 19/50 loss 0.1025325208902359 val_loss 0.13726632297039032\n",
      "Epoch 20/50 loss 0.04526679217815399 val_loss 0.13410615921020508\n",
      "Epoch 21/50 loss 0.018772436305880547 val_loss 0.136672705411911\n",
      "Epoch 22/50 loss 0.15027207136154175 val_loss 0.14336061477661133\n",
      "Epoch 23/50 loss 0.39906907081604004 val_loss 0.129362553358078\n",
      "Epoch 24/50 loss 0.6465213894844055 val_loss 0.1253126561641693\n",
      "Epoch 25/50 loss 0.051120609045028687 val_loss 0.1988091915845871\n",
      "Epoch 26/50 loss 0.03441694378852844 val_loss 0.13253343105316162\n",
      "Epoch 27/50 loss 0.03257865458726883 val_loss 0.11722975969314575\n",
      "Epoch 28/50 loss 0.01928332820534706 val_loss 0.2248697280883789\n",
      "Epoch 29/50 loss 0.006799180526286364 val_loss 0.26435717940330505\n",
      "Epoch 30/50 loss 0.01454888191074133 val_loss 0.12425501644611359\n",
      "Epoch 31/50 loss 0.0021962826140224934 val_loss 0.12580087780952454\n",
      "Epoch 32/50 loss 0.0047404286451637745 val_loss 0.11418014019727707\n",
      "Epoch 33/50 loss 0.025873633101582527 val_loss 0.10740764439105988\n",
      "Epoch 34/50 loss 0.023932036012411118 val_loss 0.1572846919298172\n",
      "Epoch 35/50 loss 0.011734743602573872 val_loss 0.2586190104484558\n",
      "Epoch 36/50 loss 0.020608816295862198 val_loss 0.14831766486167908\n",
      "Epoch 37/50 loss 0.00572209432721138 val_loss 0.10820922255516052\n",
      "Epoch 38/50 loss 0.21133050322532654 val_loss 0.1494530588388443\n",
      "Epoch 39/50 loss 0.20184586942195892 val_loss 0.1846834421157837\n",
      "Epoch 40/50 loss 0.010431881994009018 val_loss 0.11262952536344528\n",
      "Epoch 41/50 loss 0.017955029383301735 val_loss 0.09910470247268677\n",
      "Epoch 42/50 loss 0.011765846982598305 val_loss 0.10003393888473511\n",
      "Epoch 43/50 loss 0.03173711895942688 val_loss 0.1023779809474945\n",
      "Epoch 44/50 loss 0.008160700090229511 val_loss 0.10577313601970673\n",
      "Epoch 45/50 loss 2.3493640422821045 val_loss 0.12893715500831604\n",
      "Epoch 46/50 loss 0.05193275585770607 val_loss 0.12007337808609009\n",
      "Epoch 47/50 loss 0.027895521372556686 val_loss 0.09693626314401627\n",
      "Epoch 48/50 loss 0.009340161457657814 val_loss 0.12438565492630005\n",
      "Epoch 49/50 loss 0.21967695653438568 val_loss 0.10510630160570145\n",
      "Epoch 50/50 loss 0.010688438080251217 val_loss 0.09851818531751633\n",
      "Training Finished.\n"
     ]
    }
   ],
   "source": [
    "fit(50,net,lossfn,opt,train_loader,valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "cordless-innocent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network in validation data : 97 %\n",
      "Total validation data samples 149\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in valid_loader:\n",
    "        features, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(features)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network in validation data : %d %%' % (\n",
    "    100 * correct / total))\n",
    "print(\"Total validation data samples\", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-serbia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
